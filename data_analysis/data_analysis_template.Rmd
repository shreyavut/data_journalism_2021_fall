---
title: "Data Analysis Project"
author: "michael purdie, kylie rau, shreya vuttaluru"
date: "11/14/21"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

In this notebook, we are working with the [Washington Post police shooting database](https://github.com/washingtonpost/data-police-shootings) and the [Washington Post homicides database.](https://github.com/washingtonpost/data-homicides)

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}
#essential libraries
library(tidyverse)
library(janitor)
library(lubridate)
#additional libraries 
library(sf)
library(tigris)
library(tidycensus)

install.packages("usmap")
library(usmap)

install.packages("censusxy")
library(censusxy)

```

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data. 

## Quick Analysis based on loaded data: in looking at the police shootings data, everything looks relatively clean, so we don't foresee having to do any cleaning. We're choosing to focus on the geography of police shootings, so we need to use census data in order to figure out where exactly these police shootings are happening, and if there are certain neighborhoods (ex: majority-minority or low income) that are more affected by police shootings. We'll likely need to form some kind of relationship between the lat/long coordinates in this dataset and data from census tracts. 

```{r}
# Load required data
police_shootings <- read_csv("data/data-police-shootings-master/fatal-police-shootings-data.csv")

## census api key
census_api_key("82c33dd2db316b78367d3476bcb90d2abe65a69a", install = "TRUE", overwrite = TRUE)


```

## Working with the data 

``` {r}
## trying to make a map to generally understand where the shootings are
## getting some county data
counties <- counties() 
usa_counties <- counties %>%
  filter (STATEFP < "57")

## trying to fuck around with census xy

police_shootings <- read_csv("data/data-police-shootings-master/fatal-police-shootings-data.csv") %>%
    filter(!is.na(longitude)) 

## ok so it seems like we can only do one lat long at a time so... for loop? idk lets try

## first create empty data frame

police_shootings_sf <- tibble()

for (row_number in 1:nrow(police_shootings)) {
  
  #this makes a dataframe for each
  row_df<- police_shootings %>%
  slice(row_number)
  
  #store lat and long values
  longitude <- row_df$longitude
  latitude <- row_df$latitude
  census_results <- cxy_geography(longitude, latitude) %>%
    select(Census.Tracts.GEOID) %>%
    clean_names()
 
   row_df <- row_df %>%
     bind_cols(census_results) 
   
  
  #inding some rows
   police_shootings_sf <- police_shootings_sf %>%
    bind_rows(row_df) 
   
   print(paste0("finished ", row_number, " ", Sys.time()))
   
   if (row_number%%500 == 0) {
     filepath <- paste0("data/geocoded_results_", row_number, ".rds")
     write_rds(police_shootings_sf, filepath)
     police_shootings_sf <- as_tibble()
     
   }
     

}

write_rds(police_shootings_sf, "data/geocoded_results.rds")

glimpse(census_results)


## above did not work 
 
cxy_geography(longitude, latitude)

## mapping all the counties

## this is not really working rn but I am trying lol

ggplot() + 
  geom_sf(police_shootings_geom)
  geom_point(data=police_shootings, aes(x=longitude, y=latitude)) +
  geom_sf(data=usa_counties) + 
  theme_minimal() +
  geometry = geometry

```